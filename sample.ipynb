{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from model.encoder.region_detection import RegionDetection\n",
    "\n",
    "class ColorExtractor(RegionDetection):\n",
    "  '''\n",
    "  Extracts color in the given image contour\n",
    "  '''\n",
    "\n",
    "  def __init__(self, image_path, image_name):\n",
    "    super().__init__(image_path, image_name)\n",
    "    self.image_path = image_path\n",
    "    self.color_legend = self.detect_color_legend()\n",
    "\n",
    "  def extract_legend_color(self):\n",
    "    image = Image.open(self.image_path).convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    x, y, width, height = cv2.boundingRect(self.color_legend)\n",
    "    legend_roi = image_array[y:y+height, x:x+width]\n",
    "    flattened_colors = [color for row in legend_roi for color in row if not np.array_equal(color, [0, 0, 0])]\n",
    "\n",
    "    unique_colors = []\n",
    "    seen = set()\n",
    "\n",
    "    for color in flattened_colors:\n",
    "      color_tuple = tuple(color)\n",
    "\n",
    "      if color_tuple not in seen:\n",
    "        seen.add(color_tuple)\n",
    "        unique_colors.append(color)\n",
    "\n",
    "    return unique_colors\n",
    "  \n",
    "  def extract_grid_color(self):\n",
    "    # Get the bounding box of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "\n",
    "    # Crop the region of interest from the original image using the bounding box\n",
    "    cropped_image = self.image[y:y+h, x:x+w]\n",
    "\n",
    "    num_regions_y = self.yaxis_len\n",
    "    num_regions_x = self.xaxis_len\n",
    "\n",
    "    # Calculate the new dimensions that are divisible by the specified number of regions\n",
    "    new_height = (h // num_regions_y) * num_regions_y\n",
    "    new_width = (w // num_regions_x) * num_regions_x\n",
    "\n",
    "    # Resize the cropped image to the new dimensions while maintaining the aspect ratio\n",
    "    resized_image = cv2.resize(cropped_image, (new_width, new_height))\n",
    "    resized_image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Calculate the width and height of each smaller region\n",
    "    region_height = new_height // num_regions_y\n",
    "    region_width = new_width // num_regions_x\n",
    "\n",
    "    dominant_colors = []\n",
    "\n",
    "    # Extract and display each smaller region\n",
    "    for i in range(num_regions_y):\n",
    "      for j in range(num_regions_x):\n",
    "          \n",
    "        start_y = i * region_height\n",
    "        end_y = start_y + region_height\n",
    "        start_x = j * region_width\n",
    "        end_x = start_x + region_width\n",
    "        smaller_region = resized_image_rgb[start_y:end_y, start_x:end_x]\n",
    "\n",
    "        # Convert the smaller region to a 2D array of pixels\n",
    "        pixels = smaller_region.reshape((-1, 3))\n",
    "        pixels = np.float32(pixels)\n",
    "\n",
    "        # Define criteria and apply K-means clustering\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "        k = 1\n",
    "        _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "        # Get the dominant color\n",
    "        dominant_color = centers[0].astype(int).tolist()\n",
    "        dominant_colors.append(dominant_color)\n",
    "\n",
    "    return dominant_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ColorMapping(ColorExtractor):\n",
    "\n",
    "  def __init__(self, text, image_path, image_name):\n",
    "    super().__init__(image_path, image_name)\n",
    "    self.title = text.format_title()\n",
    "    self.yaxis_labels = text.clean_yaxis_label()\n",
    "    self.xaxis_labels = text.clean_xaxis_label()\n",
    "    self.legend_values = text.clean_legend_values()\n",
    "    self.yaxis_len = len(self.yaxis_labels)\n",
    "    self.xaxis_len = len(self.xaxis_labels)\n",
    "    self.colors = self.extract_legend_color()\n",
    "    self.grid_colors = self.extract_grid_color()\n",
    "\n",
    "\n",
    "  def map_legend_values(self):\n",
    "    title = self.legend_values[0]\n",
    "    legend_dict = {\"title\": title}\n",
    "    legend_dict.update({tuple(self.colors[i]): self.legend_values[i + 1] for i in range(len(self.colors))})\n",
    "    return legend_dict\n",
    "\n",
    "  def color_distance(self, color, legend_color):\n",
    "    return np.linalg.norm(np.array(color) - np.array(legend_color))\n",
    "\n",
    "  def find_closest_color(self, color, legend_dict):\n",
    "    closest_color = None\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for legend_color in legend_dict.keys():\n",
    "      if legend_color == \"title\":\n",
    "        continue\n",
    "      distance = self.color_distance(color, legend_color)\n",
    "      if distance < min_distance:\n",
    "        min_distance = distance\n",
    "        closest_color = legend_color\n",
    "    return closest_color\n",
    "\n",
    "  def map_cell_values(self):\n",
    "    legend_dict = self.map_legend_values()\n",
    "    mapped_legend_values = []\n",
    "\n",
    "    for color in self.grid_colors:\n",
    "\n",
    "      color_tuple = tuple(color)  # Convert array to tuple for dictionary key\n",
    "      closest_color = self.find_closest_color(color_tuple, legend_dict)\n",
    "\n",
    "      if closest_color is not None:\n",
    "        # mapped_legend_values.append([closest_color, legend_dict[closest_color]])\n",
    "        mapped_legend_values.append(legend_dict[closest_color])\n",
    "      else:\n",
    "        mapped_legend_values.append((color_tuple, None))  # Handle case where no close color is found\n",
    "    \n",
    "    print(mapped_legend_values)\n",
    "    return mapped_legend_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextFormatter:\n",
    "    \n",
    "  def __init__(self, text):\n",
    "    self.text = text\n",
    "\n",
    "  def format_title(self):\n",
    "    title = self.text.extract_title()\n",
    "    title = title.replace('\\n', ' ')\n",
    "    return title\n",
    "  \n",
    "  def clean_yaxis_label(self):\n",
    "    \n",
    "    yaxis_labels = self.text.extract_yaxis_labels()\n",
    "    array_yaxis = yaxis_labels.splitlines()\n",
    "    array_yaxis = [label for label in array_yaxis if label]\n",
    "    \n",
    "    return array_yaxis\n",
    "\n",
    "  def clean_xaxis_label(self):\n",
    "\n",
    "    xaxis_labels = self.text.extract_xaxis_labels()\n",
    "    array_xaxis = xaxis_labels.splitlines()\n",
    "    array_xaxis = [label for label in array_xaxis if label]\n",
    "    \n",
    "    return array_xaxis\n",
    "\n",
    "  def clean_legend_values(self):\n",
    "\n",
    "    legend_values = self.text.extract_legend_values()\n",
    "    array_legend_values = legend_values.splitlines()\n",
    "    array_legend_values = [value for value in array_legend_values if value]\n",
    "\n",
    "    return array_legend_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "class TextExtraction(RegionDetection):\n",
    "  '''\n",
    "  Extracts the text in the given region of interest.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, image_path, image_name):\n",
    "    super().__init__(image_path, image_name)\n",
    "    self.image_path = image_path\n",
    "    self.img = cv2.imread(image_path)\n",
    "    self.title_roi = self.detect_title_roi()\n",
    "    self.yaxis_roi = self.detect_yaxis_roi()\n",
    "    self.xaxis_roi = self.detect_xaxis_roi()\n",
    "    self.legend_roi = self.detect_legend_roi()\n",
    "\n",
    "    if self.img is None:\n",
    "      raise FileNotFoundError(f\"Image not found or unable to read: {image_path}\")\n",
    "\n",
    "  def preprocess_image(self):\n",
    "\n",
    "    gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "  def extract_title(self):\n",
    "\n",
    "    title_text = pytesseract.image_to_string(self.title_roi)\n",
    "    return title_text\n",
    "\n",
    "  def extract_yaxis_labels(self):\n",
    "\n",
    "    yaxis_text = pytesseract.image_to_string(self.yaxis_roi)\n",
    "    return yaxis_text\n",
    "\n",
    "  def extract_xaxis_labels(self):\n",
    "    \n",
    "    cropped_image = Image.fromarray(cv2.cvtColor(self.xaxis_roi, cv2.COLOR_BGR2RGB))\n",
    "    rotated_image = cropped_image.rotate(-90, expand=True)\n",
    "    \n",
    "    xaxis_text = pytesseract.image_to_string(rotated_image)\n",
    "    return xaxis_text\n",
    "\n",
    "  def remove_legend(self):\n",
    "\n",
    "    contour = self.detect_color_legend()\n",
    "    if contour is not None:\n",
    "      cv2.drawContours(self.image, [contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "    else:\n",
    "      print(\"No legend found in \", self.image_name)\n",
    "\n",
    "  def extract_legend_values(self):\n",
    "\n",
    "    self.remove_legend()\n",
    "    preprocessed_image = self.preprocess_image()\n",
    "    x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "    roi = preprocessed_image[y:y+h, x+w:]\n",
    "\n",
    "    roi_image = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "    custom_config = r'--psm 6 -c preserve_interword_spaces=1 --oem 3'\n",
    "    legend_text = pytesseract.image_to_string(roi_image, config=custom_config)\n",
    "\n",
    "    return legend_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.encoder.color_mapping import ColorMapping\n",
    "\n",
    "class GridProcessor(ColorMapping):\n",
    "  \n",
    "  def __init__(self, text, image_path, image_name):\n",
    "    super().__init__(text, image_path, image_name)\n",
    "    self.title = text.format_title()\n",
    "    self.yaxis_labels = text.clean_yaxis_label()\n",
    "    self.xaxis_labels = text.clean_xaxis_label()\n",
    "    self.legend_values = text.clean_legend_values()\n",
    "    self.yaxis_len = len(self.yaxis_labels)\n",
    "    self.xaxis_len = len(self.xaxis_labels)\n",
    "    self.colors = self.extract_legend_color()\n",
    "    self.grid_color = self.extract_grid_color()\n",
    "    self.mapped_grid = self.map_cell_values()\n",
    "\n",
    "  def create_grid_matrix(self):\n",
    "    cell_matrix = []\n",
    "    for j in range(self.yaxis_len):\n",
    "      for i in range(self.xaxis_len):\n",
    "        index = j * self.xaxis_len + i  # Calculate the index for 1D list\n",
    "        mapped_value = self.mapped_grid[index]  # Access the 1D list element\n",
    "        cell_matrix.append([self.yaxis_labels[j], self.xaxis_labels[i], mapped_value, self.title])\n",
    "    return cell_matrix\n",
    "\n",
    "  def flatten_list(self, nested_list):\n",
    "    return [item for sublist in nested_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class RegionDetection:\n",
    "  '''\n",
    "  Identifies the region of interest for the extraction of text\n",
    "  '''\n",
    "\n",
    "  def __init__(self, image_path, image_name):\n",
    "    self.image_path = image_path\n",
    "    self.image_name = image_name\n",
    "    self.image = cv2.imread(self.image_path)\n",
    "    self.contours = self.find_contours()\n",
    "    self.image_np = np.array(self.image)\n",
    "    self.largest_contour = self.detect_grid()\n",
    "\n",
    "  def find_contours(self):\n",
    "\n",
    "    gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours\n",
    "\n",
    "  def detect_grid(self):\n",
    "\n",
    "    largest_contour = max(self.contours, key=cv2.contourArea)\n",
    "    return largest_contour\n",
    "  \n",
    "  def detect_color_legend(self):\n",
    "  \n",
    "    # Calculate areas for all contours\n",
    "    contours_with_areas = [(contour, cv2.contourArea(contour)) for contour in self.contours]\n",
    "    \n",
    "    # Sort contours by area in descending order\n",
    "    sorted_contours = sorted(contours_with_areas, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the second largest contour if it exists\n",
    "    if len(sorted_contours) > 1:\n",
    "      second_largest_contour = sorted_contours[1][0]\n",
    "      return second_largest_contour\n",
    "\n",
    "  # Displays the region of interest\n",
    "  def draw_bounding_box(self, roi):\n",
    "\n",
    "    # Convert the ROI to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the bounding box coordinates\n",
    "    x, y, w, h = cv2.boundingRect(gray_roi)\n",
    "    \n",
    "    # Debug: Print the coordinates\n",
    "    print(f\"Bounding Box Coordinates: x={x}, y={y}, w={w}, h={h}\")\n",
    "    \n",
    "    # Draw the bounding box on the original image\n",
    "    cv2.rectangle(self.image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Debug: Display the grayscale ROI\n",
    "    plt.imshow(gray_roi, cmap='gray')\n",
    "    plt.title(\"Grayscale ROI\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "  def detect_title_roi(self):\n",
    "    \n",
    "    if self.largest_contour is not None:\n",
    "      x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "      top = max(0, y - h)\n",
    "      title_roi = self.image_np[top:y, :]\n",
    "\n",
    "      return title_roi\n",
    "  \n",
    "  def detect_yaxis_roi(self):\n",
    "\n",
    "    if self.largest_contour is not None:\n",
    "      x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "      left = max(0, x - w)\n",
    "      yaxis_roi = self.image_np[y:y + h, left:x]\n",
    "\n",
    "      return yaxis_roi\n",
    "\n",
    "  def detect_xaxis_roi(self):\n",
    "\n",
    "    if self.largest_contour is not None:\n",
    "      x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "      bottom = min(self.image_np.shape[0], y + 2 * h)\n",
    "      xaxis_roi = self.image_np[y + h:bottom, x:x + w]\n",
    "\n",
    "      return xaxis_roi\n",
    "\n",
    "  def detect_legend_roi(self):\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "    right = max(self.image.shape[1], x + 2 * w)\n",
    "    legend_roi = self.image[y:y + h, x + w:right]\n",
    "\n",
    "    return legend_roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from model.preprocessor.data_preprocessing import DataPreprocessing, Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "  '''\n",
    "  Converts the annotation and extracted texts from images into tokens or sequence\n",
    "  '''\n",
    "  def __init__(self, csv_dir, img_dir):\n",
    "    self.csv_dir = csv_dir\n",
    "    self.img_dir = img_dir\n",
    "    spacy.prefer_gpu()\n",
    "    self.spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "  def read_csv(self, file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "  \n",
    "  @property\n",
    "  def preprocess_data(self):\n",
    "    all_img_data, all_annotation_data = self.collect_data\n",
    "    print(all_annotation_data)\n",
    "    return all_img_data, all_annotation_data\n",
    "\n",
    "  @property\n",
    "  def collect_data(self): # Returns tokenized img data, and annotation data\n",
    "    img_data = []\n",
    "    annotation_data = []\n",
    "    df = self.read_csv(self.csv_dir)\n",
    "\n",
    "    for _, row in df.iloc[0:2].iterrows():\n",
    "      image_name = row.iloc[0]\n",
    "      image_path = os.path.join(self.img_dir, image_name)\n",
    "\n",
    "      values = TextExtraction(image_path, image_name)\n",
    "      clean_values = TextFormatter(values).clean_xaxis_label()\n",
    "      matrix_values = GridProcessor(clean_values, image_path, image_name).create_grid_matrix()\n",
    "      img_data.append(matrix_values)\n",
    "\n",
    "    return img_data, annotation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'format_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     23\u001b[0m   input_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 24\u001b[0m   \u001b[43mHeatmapEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[79], line 11\u001b[0m, in \u001b[0;36mHeatmapEncoder.run_main\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_main\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m   data \u001b[38;5;241m=\u001b[39m \u001b[43mDataPreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_img_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_data\u001b[49m\n",
      "Cell \u001b[1;32mIn[76], line 34\u001b[0m, in \u001b[0;36mDataPreprocessing.collect_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m   values \u001b[38;5;241m=\u001b[39m TextExtraction(image_path, image_name)\n\u001b[0;32m     33\u001b[0m   clean_values \u001b[38;5;241m=\u001b[39m TextFormatter(values)\u001b[38;5;241m.\u001b[39mclean_xaxis_label()\n\u001b[1;32m---> 34\u001b[0m   matrix_values \u001b[38;5;241m=\u001b[39m \u001b[43mGridProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_grid_matrix()\n\u001b[0;32m     35\u001b[0m   img_data\u001b[38;5;241m.\u001b[39mappend(matrix_values)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_data, annotation_data\n",
      "Cell \u001b[1;32mIn[70], line 6\u001b[0m, in \u001b[0;36mGridProcessor.__init__\u001b[1;34m(self, text, image_path, image_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, image_path, image_name):\n\u001b[1;32m----> 6\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mformat_title()\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaxis_labels \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mclean_yaxis_label()\n",
      "File \u001b[1;32md:\\heatmap-textual-description\\model\\encoder\\color_mapping.py:8\u001b[0m, in \u001b[0;36mColorMapping.__init__\u001b[1;34m(self, text, image_path, image_name)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, image_path, image_name):\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(image_path, image_name)\n\u001b[1;32m----> 8\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_title\u001b[49m()\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaxis_labels \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mclean_yaxis_label()\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis_labels \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mclean_xaxis_label()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'format_title'"
     ]
    }
   ],
   "source": [
    "\n",
    "class HeatmapEncoder:\n",
    "\n",
    "  def __init__(self, input_dir):\n",
    "    self.train_csv_path = \".\\\\data\\\\ground_truth\\\\train\\\\annotation.csv\"\n",
    "    self.train_img_dir = \".\\\\data\\\\images\\\\train\"\n",
    "    self.max_len = 0\n",
    "\n",
    "\n",
    "  def run_main(self):\n",
    "    \n",
    "    data = DataPreprocessing(self.train_csv_path, self.train_img_dir).collect_data\n",
    "    \n",
    "    # Data Preprocessing\n",
    "    # \n",
    "\n",
    "    # Training\n",
    "\n",
    "    # Save every epoch or after the training?\n",
    "\n",
    "    # Testing\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  input_dir = \".\\\\data\\\\images\\\\train\"\n",
    "  HeatmapEncoder(input_dir).run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class ROI:\n",
    "  '''\n",
    "  Identifies the region of interest for the extraction of text\n",
    "  '''\n",
    "\n",
    "  def __init__(self, image_path):\n",
    "    self.image_path = image_path\n",
    "    self.image = cv2.imread(self.image_path)\n",
    "    self.contours = self.find_contours()\n",
    "    self.image_np = np.array(self.image)\n",
    "    self.largest_contour = self.detect_grid()\n",
    "\n",
    "  def find_contours(self):\n",
    "\n",
    "    gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours\n",
    "\n",
    "  def detect_grid(self):\n",
    "    max_area = 0\n",
    "    largest_contour = None\n",
    "\n",
    "    for contour in self.contours:\n",
    "      area = cv2.contourArea(contour)\n",
    "\n",
    "      if area > max_area:\n",
    "        max_area = area\n",
    "        largest_contour = contour\n",
    "\n",
    "    return largest_contour\n",
    "  \n",
    "  def detect_color_legend(self):\n",
    "  \n",
    "    for contour in self.contours:\n",
    "      area = cv2.contourArea(contour)\n",
    "\n",
    "      if 1000 < area < 10000:\n",
    "        return contour\n",
    "\n",
    "  # Display the cropped region of interest\n",
    "  def draw_bounding_box(self, roi):\n",
    "\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    x, y, w, h = cv2.boundingRect(gray_roi)\n",
    "    cv2.rectangle(self.image_np, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    plt.imshow(cv2.cvtColor(self.image_np, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Bounding Box\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "  \n",
    "  def detect_title_roi(self):\n",
    "    \n",
    "    if self.largest_contour is not None:\n",
    "      x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "      top = max(0, y - h)\n",
    "      title_roi = self.image_np[top:y, :]\n",
    "\n",
    "      return title_roi\n",
    "  \n",
    "  def detect_yaxis_roi(self):\n",
    "\n",
    "    if self.largest_contour is not None:\n",
    "      x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "      left = max(0, x - w)\n",
    "      yaxis_roi = self.image_np[y:y + h, left:x]\n",
    "\n",
    "      return yaxis_roi\n",
    "\n",
    "  def detect_xaxis_roi(self):\n",
    "\n",
    "    if self.largest_contour is not None:\n",
    "      x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "      bottom = min(self.image_np.shape[0], y + 2 * h)\n",
    "      xaxis_roi = self.image_np[y + h:bottom, x:x + w]\n",
    "\n",
    "      return xaxis_roi\n",
    "\n",
    "  def detect_legend_roi(self):\n",
    "    if self.largest_contour is not None:\n",
    "      x, y, w, h = cv2.boundingRect(self.largest_contour)\n",
    "      right = max(self.image_np.shape[1], x + 2 * w)\n",
    "      legend_roi = self.image_np[y:y + h, x + w:right]\n",
    "      self.draw_bounding_box(legend_roi)\n",
    "\n",
    "      # Crop the image and return a copy without modifying the original\n",
    "    return legend_roi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
